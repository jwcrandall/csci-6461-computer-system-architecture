\documentclass[fontsize=5pt]{scrartcl}
\usepackage{lmodern}
%\documentclass[10pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[margin=0.25in]{geometry}        % See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}                     % ... or a4paper or a5paper or ... 
\geometry{landscape}                        % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}                       % Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{esint}                          %for cyclic integrals
\usepackage{ amssymb } 
\usepackage[usenames, dvipsnames]{color}
\usepackage{multicol}
\usepackage{color,soul}
\usepackage{siunitx}                        % Scientific Notation
\usepackage{graphicx}

\def\rcurs{{\mbox{$\resizebox{.16in}{.08in}{\includegraphics{ScriptR}}$}}}
\def\brcurs{{\mbox{$\resizebox{.16in}{.08in}{\includegraphics{BoldR}}$}}}
\def\hrcurs{{\mbox{$\hat \brcurs$}}}

\begin{document}
\colorbox{YellowGreen}{Joe Crandall's CSCI 6461 Computer System Architecture}
\colorbox{Thistle}{Used Heavily}
\colorbox{Cyan}{Topic}
\colorbox{Orange}{SubTopic}
\colorbox{Aquamarine}{KNOWTHISMATH}
\colorbox{RubineRed}{Definition/Constant/Units}
\colorbox{Yellow}{break}
\colorbox{Cyan}{0518 Lecture 1 Introduction} 
Computer Architecture: Functional operation of the individual HW units within a computer system, and the flow of information and control among them.
\hl{I} 
Program Counter (PC): address of next instruction to be executed
\hl{I}
Condition Code (CC): set when arithmetic/logical operations are executed, four 1 bit elements, Overflow, Underflow, Divzero, EqualOrNot
\hl{I}
Instruction Register (IR): holds instruction to be executed
\hl{I}
Memory Address Register (MAR): holds the address of the word  to be fetched from memory
\hl{I}
Memory Buffer Register (MBR): holds the word just fetched from or the word to be last stored into memory
\hl{I}
general purpose registers (GPR0$\ldots$GPR3): mnemonically referred to, may be used as accumulators.
\hl{I}
machine fault register (MFR): contains the ID code of a machine fault after it occurs
\hl{I}
index registers: (X1$\ldots$X3): contains a base address that supports register addressing of memory.
\hl{I}
Instruction execution cyle: instruction fetch - obtain instruction from program storage, instruction decode - determine requiered actions and instruction size, operand fetch - locate and obtain operand data, execute - compute result value or status, result store - deposit results in storage for later use, next instruction - deterine sucessor instruction.
\colorbox{Cyan}{0523 Lecture 2 Basic System Design}
The simplest shifter is the shift register, which can shift by one position per clock cycle
\hl{I}
Performance, Resposne Time, Throughput, Execution Times
\hl{I}
Instruction Set Architecture, Processors, Memory, I/O Systems
\hl{I}
Finding the absolute value of an integer: abs - str	r0,0,$<$tempInt$>$; store r0 in $<$tempInt$>$, some location - ldr	r1,0,smask; mask for sign bit = 100 000 000 000 000 000 - and r1,r0; AND r1 and r0: if r0 bit is set it will be set in r1 - jz r1,0,pos; test if sign = 0, e.g., r0 bit 0 is 0 - src r0,1,1,1; shift r0 logical left 1 bit - src r0,1,0,1; shift r0 logical right – sets sign bit to 0
\hl{I}
Instruction format: 0...5 Operation Code (OP), 6 7 General Purpose Register (R), 8 9 Index Register (I), 10 Indirect Bit (I), 11 ... 15 Address - a binary number also referred to as immediate
\hl{I}
Effective Address (EA) = contents of Address field plus contents of the index register specified in the IX field – here it is 10 + 2 or 13
\colorbox{Cyan}{0525 Lecture 3 Instruction Set Architecture} ISA is that portion of the machine visible to the assembly level programmer or to the compiler writer
\hl{I}
Challenges: Silicon Real Estate, Cost, Expandability, Legacy Support, Complexity
\hl{I}
The encoding of these instructions is one of the major tasks in instruction set design and requires very careful thought
\hl{I}
Instruction must specify: Which operation to perform, Where to find the operands (registers, memory, immediate, stack, other), Where to store the result (registers, memory, immediate, stack, other), Location of next instruction (either implicitly or explicitly)
\hl{I}
Types of Instructions: Transfer of control: jumps, calls | Arithmetic/Logical – add, subtract, multiply, divide, sqrt, log, sin, cos, ….; also, Boolean comparisons | Load/Store: load a value from memory or store a value to memory | Stack instructions: push/pop | System: traps, I/O, halt, no-operation | Floating Point Arithmetic | Decimal | String operations | Multimedia operations: Intel’s MMX and Sun’s VIS
\hl{I}
Multiple ways to add C = B + A: Stack Push A Push B Add Pop C | Accumulator Load A Add B Store C | Register (Register-memory) Load R1 A Add R1 B Store C R1 | Register (load-store) Load R1 A Load R2 B Add R3 R1 R2 Store C R3
\hl{I}
Stack Architecture: Need Top of Stack register, Stack Limit register, Pros Good code density (implicit operand addressing top of stack, Low hardware requirements, Easy to write a simple compiler for stack architectures, Cons, Stack becomes the bottleneck, Little ability for parallelism or pipelining, Data is not always at the top of stack when needed, so additional instructions are needed
\hl{I}
Accumulator Architectures: One or more accumulators (masquerade as GPRs), Pros Very low hardware requirements, Easy to design and understand, Cons, Accumulator becomes the bottleneck, Little ability for parallelism or pipelining, High memory traffic
\hl{I}
Memory-Memory Architectures: Operands fetched directly from memory into internal registers Pros, Requires fewer instructions (especially if 3 operands), Easy to write compilers for (especially if 3 operands), Cons Very high memory traffic (especially if 3 operands), Variable number of clocks per instruction (especially if 2 operands) and indexing and indirect access and , With two operands, more data movements are required
\hl{I}
Register-Memory Architectures: Operands fetched from register and memory Pros Some data can be accessed without loading first, Instruction format easy to encode, Good code density, Cons Operands are not equivalent (poor orthogonality), Variable number of clocks per instruction (w/ indexing and indirect access and), May limit number of registers 
\hl{I}
Load-Store/Register-Register Architectures: Operands fetched only from registers which are pre-loaded Pros Simple, fixed length instruction encoding, Instructions take similar number of cycles, Relatively easy to pipeline, Cons Higher instruction count , Not all instructions need three operands, Dependent on good compiler
\hl{I}
Addressing Types: Register Direct Addressing: The Register contains the operand, Direct Addressing to Main Memory: Instruction contains the Main Memory Address, Indirect Addressing To Main Memory: Instruction contains an address in main memory whose contents are the address of the operand
\hl{I}
Compilation Steps: Parsing intermediate representation, Jump Optimization, Loop Optimizations, Register Allocation, Code Generation assembly code, Common SubExpression, Procedure in-lining, Constant Propagation, Strength Reduction, Pipeline Scheduling 
\hl{I}
ISA Metrics: Orthogonality, completeness, regularity, streamlined design, ease of compilation
\hl{I}
ISA Design Space: number of explicit operands, operand storage, effective address, type and size of operands, operations.
\colorbox{Cyan}{0601 Lecture 4 Memory Systems} Memory System Design: Key Ideas: The Principle of Locality: Programs access a relatively small portion of the address space at any instant of time. Instructions and data both exhibit spatial and temporal locality. Temporal locality: If a particular instruction or data item is used now, there is a good chance that it will be used again in the near future. Spatial locality: If a particular instruction or data item is used now, there is a good chance that the instructions or data items that are located in memory immediately following or preceding this item will soon be used. Therefore, it is a good idea to move such instruction and data items that are expected to be used soon from slow memory to fast memory (cache). BUT! This is prediction, and therefore will not always be correct – depends on the extent of locality.
\hl{I}

\colorbox{Cyan}{0606 Lecture 6 I/O Systems}

\colorbox{Cyan}{0608 Lecture MIPS}

\colorbox{Cyan}{0608 Lecture Pipelines}

\colorbox{Cyan}{0613 Lecture Branch Prediction}

\colorbox{Cyan}{0613 Lecture Exploiting Instruction Level Parallelism with Software Approaches}

\colorbox{Cyan}{0613 Lecture Instruction Level Parallelism}

\colorbox{Cyan}{0613 Lecture 8 Instruction Level Parallelism}

\colorbox{Cyan}{0613 Lecture Pipelines}

\colorbox{Cyan}{0615 Lecture 5 Instruction Level Parallelism and Its Dynamic Exploitation}

\colorbox{Cyan}{0615 Lecture 5 Overcoming Data Hazards with Dynamic Scheduling}

\colorbox{Cyan}{0615 Lecture Tomasulo}

\colorbox{Cyan}{0622 Lecture 9 Vector Operations}

\colorbox{Cyan}{0627 Lecture 10 High Performance Computing}

\colorbox{Cyan}{0629 Lecture Cache Coherency Snooping}

\colorbox{Cyan}{0629 Lecture Snooping Protocol Directory Protocol Synchronization Consistency}

\colorbox{Cyan}{0629 Sample Final}
\colorbox{Orange}{Superscalar Architectures}
\textbf{Q.} a. Supplemental figure 2 has an illustration of a Tomasulo example discussed in class. How does the Tomasulo algorithm accomplish register renaming? 
\hl{I}
\textbf{A.} Registers are sources for operands. Registers are limited in number. Instructions are issued to reservation stations along with operand values. Reservation stations are then the sources of operands and computation results, with respect to registers.
\hl{I}
\textbf{Q.} b. Explain how the Tomasulo hardware makes maximum use of execution unit hardware, that is keeps the functional units busy.
\hl{I}
\textbf{A.} It issues instructions to reservation stations. Multiple instructions at any point in time may be waiting in reservation stations. Each reservation station may feed multiple functional units. The functional units operate in parallel. Functional units execute as soon as all operands are available.
\hl{I}
\textbf{Q.} c. How does a reorder buffer preserve exception behavior?
\hl{I}
\textbf{A.} The reorder buffer (ROB) stores exceptions from a reservation station execution and does not allow the exception until the offedning instruction is commited.
\colorbox{Orange}{Cache Coherency (Multiprocessors or Multicores)} 
\textbf{Q.} a. What types of cache coherency is used in massively parallel architectures and why?
\hl{I}
\textbf{A.} Bus snooping is not used. What is used is message passing distributed memory that is shared and a directory per processor that manages its local memory.
\hl{I}
\textbf{Q.} b. In a snooping protocol, why are write misses always put on the bus?
\hl{I}
\textbf{A.} This allows other processors caches to see the miss and invalidate their copies.
\colorbox{Orange}{Vector Processors}
\textbf{Q.} a. Explain why vector processors are much more efficient than compiler optimizations of loops and dynamic scheduling in scalar architectures.
\hl{I}
\textbf{A.} One instruction fetch causes multiple executions that would have been put in a loop in a scalar processor. Modern vector processors have optimized memory fetch/store hardware.
\hl{I}
\textbf{Q.} b. Briefly explain how vector units can accomplish forwarding?
\hl{I}
\textbf{A.} Using  a detection scheme similar to the forwarding unit in a scalar pipeline, outputs of functional units can be chained to inputs of other units based upon dependencies detected.
\colorbox{Orange}{Branch Prediction}
\textbf{Q.} a. How does a branch target buffer eliminate invalid stage executions? 
\hl{I}
\textbf{A.} In Microprocessor without Interlocked Pipelined Stages (MIPS) the predictive location of the next instruction to be executed as a result of the branch is known at the end of the instruction fetch (IF) stage of the branch instruction an can be routed to the program counter (PC).
\hl{I}
\textbf{Q.} b. Why does a 4 state (2 bit) branch predictor do much better than a 2 state (1 bit) branch predictor?
\hl{I}
\textbf{A.} A 1 bit predictor will invert the bit if the prediction is wrong and backward branches for loops will be mispredicted twice. A 2 bit predictor allows for more information about tendencies. A prediction must miss twice before it is changed. It performs better for backward branches of loops.
\hl{I}
\textbf{Q.} c. What penalties do we pay for incorrect predictions with a reorder buffer?
\hl{I}
\textbf{A.} At the commit of a branch if the prediction was incorrect, we clear all subsequent values in the reorder buffer (ROB). All computations beyond the incorrect branch must be redone.
\colorbox{Orange}{Static Code Optimization}
\textbf{Q.} Assume a standard Microprocessor without Interlocked Pipelined Stages (MIPS) architecture that we used in examples in class with branch determination and execution done in the second clock cycle for an instruction. Unroll the following loop once and shcedule (re-order) the instructions to maximize processor performance. Note that the loop is correct as is, and other possible optimizations may be possible. How many cycles are requiered to completely execute the unrolled loop once?
\hl{I}
loop: ld $r 6,0(r l)$
\hl{I}
ld $\mathbf{r} 2,0(\mathrm{r} 8)$
\hl{I}
add $r 6, r 6, r 2$
\hl{I}
st $r 6,0(r 1)$
\hl{I}
daddui r l.r1, #8
\hl{I}
bne $r$. $r$, loop
\hl{I}
\textbf{A.}
\colorbox{Orange}{Memory Hierarchy}
\textbf{Q.} a. What basic concept or concepts throughout the memory hierarchy dictate where copies of memory should be kept?
\hl{I}
\textbf{A.} Locality, temporal and spatial
\hl{I}
\textbf{Q.} b. What happens to cache performance when the number of blocks in a direct mapped cache are reduced?
\hl{I}
\textbf{A.} The cache is the same size, the blocks are larger, and compulsory misses are higher. Capacity misses go up and conflict misses go up.
\hl{I}
\textbf{Q.} c. For b, how does this affect other optimizations in instruction scheduling and execution units?
\hl{I}
\textbf{A.} The miss rate impacts execution in the pipeline and prefetch works better.


\end{document}  